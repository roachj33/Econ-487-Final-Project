---
title: "Econ 487 Final Project"
author: "Mateo Delaroca/Cloris Li/Joey Roach"
date: "12/11/2020"
output: html_document
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("plyr")
#install.packages("RColorBrewer")
#install.packages("sf")
#install.packages("maps")
#install.packages("viridis")
#install.packages("rnaturalearth")
#install.packages("rnaturalearthdata")
#install.packages("rgeos")
#install.packages("tidyr")
#install.packages("chron")
#install.packages("heatmaply")
library(lubridate)
library(chron)
library(sf)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(knitr)
library(maps)
library(viridis)
library(rnaturalearth)
library(rnaturalearthdata)
library(rgeos)
library(mapproj)
library(tidyr)
library(heatmaply)


# setwd("~/R/Econ487Project")
# wd <-getwd()
```

```{r}
# To read our dataframes 

#retail_csv <- read.csv("~/R/Econ487project/online_retail.csv")
retail_csv <- read.csv("online_retail.csv")

# Create revenue variable
retail_csv$revenue <- retail_csv$UnitPrice * retail_csv$Quantity
```

### World map for revenue visualization:
```{r eval = T}
#World map revenues graph
retail_df <- retail_csv

retail_df$revenue <- retail_df$UnitPrice*retail_df$Quantity

retail_df_country<- retail_df %>%select(Country,revenue)%>% group_by(Country) %>% summarise(revenue=sum(revenue)) 
```

```{r eval = F}
# making the country names consistent

retail_df_country[29,1] <- "South Africa"

retail_df_country[11,1]<- "Ireland"

retail_df_country[36,1] <- "UK"

retail_df_country$revenue <- log(retail_df_country$revenue)

world_map <-map_data("world") %>% filter(region != "Antartica") %>% fortify


#retail_map <- merge(retail_df_country,world_map,by="Country") , had to convert to log(revenue) as there was one outlier 

revenue_country_plot <- ggplot()+ geom_map(data=world_map,map=world_map,aes(x=long,y=lat,group=group,map_id=region),fill="white",color="grey",size=0.5)+
        geom_map(data=retail_df_country,map=world_map,aes(fill=revenue,map_id=Country),color="grey",size=0.5)+
        coord_map("rectangular",late0=0,xlim=c(-180,180),ylim=c(-60,90))+
        scale_fill_continuous(low="yellow",high="darkred",guide="colorbar")+scale_x_continuous(breaks = c())+
        scale_y_continuous(breaks = c()) +labs(fill="Log revenue",title="Log Revenue by country",x="",y="")+theme_bw()
       
revenue_country_plot 
```

### Consumer view: top 4/10 consumers and their share contribution to the revenue
```{r eval = T}
# Investigating customer sales
customer_view <- retail_csv %>%
  group_by(CustomerID) %>%
  summarise(total_revenue = sum(revenue),
            avg_revenue = mean(revenue),
            total_quantity = sum(Quantity),
            avg_quantity = mean(Quantity),
            num_transactions = length(Quantity),
            num_unique_items = length(unique(Description)))
# Get a sense of the figures.
customer_view[order(-customer_view$total_revenue),]
# Looks like there is about 135,000 missing customer IDS on 
# transactions. Drop those NA's.
customers_complete <- customer_view %>%
  na.omit(customer_view)
# Order according to decreasing revenue
customers_complete <-
  customers_complete[order(-customers_complete$total_revenue), ]

# Grab top 4, top 10 customers by revenue
top_4_customers <- customers_complete[1:4, ]
top_4_customers <- top_4_customers$CustomerID
top_4_customers
top_10_customers <- customers_complete[1:10, ]
top_10_customers <- top_10_customers$CustomerID
top_10_customers
# Compare the revenues generated by these customers relative to
# all other customers
retail_csv$istop4 <- retail_csv$CustomerID %in% top_4_customers
#retail_csv
retail_csv$istop10 <- retail_csv$CustomerID %in% top_10_customers
total_revenue <- sum(retail_csv$revenue)
top_4_revenue <- retail_csv %>%
  group_by(istop4) %>%
  summarise(share_of_revenue = sum(revenue) / total_revenue)
top_4_revenue
top_10_revenue <- retail_csv %>%
  group_by(istop10) %>%
  summarise(share_of_revenue = sum(revenue) / total_revenue)
top_10_revenue

# Visualizations of consumer data
top_4_data <- data.frame(in_top_4 = top_4_revenue$istop4,
                         share_of_revenue =
                           top_4_revenue$share_of_revenue)
top_10_data <- data.frame(in_top_10 = top_10_revenue$istop10,
                          share_of_revenue =
                            top_10_revenue$share_of_revenue)
top_4_pie <- ggplot(top_4_data, aes(x="",
                                    y=share_of_revenue,
                                    fill = in_top_4)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = round(share_of_revenue * 100, 2)),
            size=5, position = position_stack(vjust = 0.5)) +
  labs(x = NULL, y = NULL,
       title = "Share of Total Revenue by Top 4 Customers")
top_4_pie

top_10_pie <- ggplot(top_10_data, aes(x="",
                                      y=share_of_revenue,
                                      fill = in_top_10)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = round(share_of_revenue * 100, 2)),
            size = 5, position = position_stack(vjust = 0.5)) +
  labs(x = NULL, y = NULL,
       title = "Share of Total Revenue by Top 10 Customers")
top_10_pie
```

##### Function to calculate the percentage of time two items are sold together(used later to see bunling patterns)
```{r eval = T}
#Sold together function, it takes the product names as strings
pair_function <-  function(product1,product2) {

product_1_dataframe <- retail_df %>% filter(Description == product1) %>%filter(Quantity>0) %>% group_by(InvoiceNo) %>% summarise(sum(Quantity))

product_2_dataframe <- retail_df %>% filter(Description == product2) %>%filter(Quantity>0) %>% group_by(InvoiceNo) %>% summarise(sum(Quantity))

product_1_2_dataframe <- merge(product_1_dataframe, product_2_dataframe, by= "InvoiceNo")


percentage_1 <- round(nrow(product_1_2_dataframe)/nrow(product_1_dataframe) *100, digits = 2)

percentage_2 <- round(nrow(product_1_2_dataframe)/nrow(product_2_dataframe) *100, digits = 2)


report_statement_1 <- paste(product1,"is sold ",percentage_1, " % of the time with",product2 )

report_statement_2 <- paste(product2, "is sold", percentage_2, " % of the time with",product1)

print(report_statement_1)

print(report_statement_2)
}

#examples using random products:

pair_function(product1 = "REGENCY CAKESTAND 3 TIER", product2= "PARTY BUNTING")

pair_function(product1 = "REGENCY TEA PLATE ROSES ", product2= "REGENCY TEAPOT ROSES ")

pair_function(product1 = "3D SHEET OF DOG STICKERS", product2= "3D SHEET OF CAT STICKERS")


pair_function(product1= "REGENCY CAKESTAND 3 TIER",product2="REGENCY CAKESTAND 3 TIER" )


pair_function(product1 = "PARTY BUNTING", product2= "PARTY BUNTING")

```

### Price trend: by month and by hour
```{r eval = T}
retail_day <- retail_df %>% filter(!is.na(InvoiceDate)) %>% filter(Description == c("REGENCY CAKESTAND 3 TIER","PARTY BUNTING","WHITE HANGING HEART T-LIGHT HOLDER","JUMBO BAG RED RETROSPOT"))

retail_day$InvoiceDate <- as.POSIXct(retail_day$InvoiceDate, format = "%m/%d/%Y %H:%M")

retail_day$hour <- hour(retail_day$InvoiceDate)

retail_day$minute <- minute(retail_day$InvoiceDate)

retail_day$month <- month(retail_day$InvoiceDate)

retail_hour <-retail_day %>% group_by(hour,Description) %>% summarise(Average_price=mean(UnitPrice))

price_time_chart <- ggplot(data=retail_hour,mapping = aes(x=hour,y=Average_price))+geom_point(mapping = aes(x=hour,y=Average_price))+ geom_line(aes(color=Description))+

    scale_x_continuous(limits=c(6,20), breaks = seq(6,20,2))+
  theme(axis.text.x = element_text(face="bold", color="#993333",size=14, angle=45))+ labs(y="Average Price(2010-2011)")+ labs(title = "Price by Hour" )

  
price_time_chart

retail_month <- retail_day %>% group_by(month,Description) %>% summarise(Average_price=mean(UnitPrice))

price_time_chart_month <- ggplot(retail_month,
                                 aes(x=month, y=Average_price)) +
  geom_point(aes(x=month, y=Average_price)) +
  geom_line(aes(color=Description)) +
  scale_x_continuous(limits=c(1,12), breaks = seq(0,12,2),labels = c("Jan","Feb","Apr","Jun","Aug","Oct","Dec"))+
  theme(axis.text.x = element_text(face="bold", color="#993333",size=14, angle=45))+ labs(y="Average Price(2010-2011)")

price_time_chart_month

#customer time chart

top_sales <- retail_df %>% filter(CustomerID %in% top_4_customers) 

top_sales$InvoiceDate <- as.Date(top_sales$InvoiceDate, format = "%m/%d/%y")
top_sales$Month <- month(top_sales$InvoiceDate)


top_sales <- top_sales%>% group_by(CustomerID,Month) %>% summarise(revenue=sum(revenue))

top_sales$CustomerID <- as.character(top_sales$CustomerID)

top_sales_plot <- ggplot(data=top_sales,mapping =aes(x=Month,y=revenue)) +geom_point()+geom_line(aes(color=CustomerID))+scale_x_continuous(limits=c(1,12), breaks = seq(0,12,2),labels = c("Jan","Feb","Apr","Jun","Aug","Oct","Dec"))+
  theme(axis.text.x = element_text(face="bold", color="#993333",size=14, angle=45))+labs(title = "Price" )

top_sales_plot

top_sales_deviation <- top_sales %>% group_by(CustomerID) %>% summarise(deviation=sd(revenue))

top_sales_deviation

mean(top_sales_deviation$deviation)

```

### Product view: top 4 selling product and percentage of revenue they account for
```{r eval = T}
retail <- retail_csv
retail$Revenue <- retail$UnitPrice * retail$Quantity

# Might need to exclude obs with negative sales or zero price in original retail for product side, but will keep them for now to find top 4 selling product
# retail_complete <- retail %>% filter(UnitPrice > 0, Quantity > 0, Revenue > 0)

# Summary stats for each product(i.e. StockCode), sort by revenue
product_summary <- retail %>% 
    group_by(StockCode) %>% 
    summarise(min_price = min(UnitPrice),
              mean_price = mean(UnitPrice),
              max_price = max(UnitPrice),
              sd_price = sd(UnitPrice),
              min_qty = min(Quantity),
              mean_qty = mean(Quantity),
              max_qty = max(Quantity),
              obs = length(UnitPrice),
              total_rev = sum(Revenue)) %>%
  arrange(-total_rev)

# Get top 4 selling product (excluding "DOT")
top4_product <- product_summary[2:5, ] %>% select(StockCode)
top4_product <- as.vector(top4_product$StockCode)

# **Checking product description and cleaning a bit: 
# top 4 StockCode (22423, 47566, 85123A, 85099B)
temp <- retail %>% filter(StockCode == top4_product[3])
temp %>% group_by(Description) %>% summarise(obs = length(Quantity))

# StockCode: (Actual) Description
# 1. [22423]: "REGENCY CAKESTAND 3 TIER" (2200/2203 transactions, 3 damages/faulty)
# 2. [47566]: "PARTY BUNTING"
# 3. [85123A]: "WHITE HANGING HEART T-LIGHT HOLDER" 
#              (2302/2313 transactions, others mislabeled)
#              * also same product but StockCode [85123a]
# 4. [85099B]: "JUMBO BAG RED RETROSPOT"

top4_product <- c("REGENCY CAKESTAND 3 TIER",
                  "PARTY BUNTING",
                  "WHITE HANGING HEART T-LIGHT HOLDER",
                  "JUMBO BAG RED RETROSPOT")
# Biggest sales comes from party decorations and accesories?

# New column for top products rank
retail$isTop <- rep(0, nrow(retail))
for (i in 1:4){
  retail$isTop[retail$Description == top4_product[i]] <- i
}

# Percentage of revenue that each Top 4 product accounts for:
percent_sales <- data.frame(top4_product)
percent_sales$percentage <- rep(0, 4)
for (i in 1:4){
  sales <- sum(retail %>% filter(isTop == i) %>% select(Revenue))
  percent_sales[i, 2] <- sales / sum(retail$Revenue)
}
percent_sales

### pie chart for presentation ###

custom_df <- retail_df %>% group_by(Description) %>%summarise(revenue=sum(revenue)) %>% filter(revenue > 0)

unique_custom <- c(unique(custom_df$Description))

custom_df$percentage <- custom_df$revenue/sum(custom_df$revenue)


custom_df$top4 <- custom_df$Description %in% top4_product

custom_df <- custom_df %>% group_by(top4) %>% summarise(percentage=sum(percentage))

pie_plot_products <- ggplot(custom_df, aes(x="",
                                    y=percentage,
                                    fill = top4)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = round(percentage * 100, 2)),
            size=5, position = position_stack(vjust = 0.5)) +
  labs(x = NULL, y = NULL,
       title = "Share of Total Revenue by Top 4 Products")
pie_plot_products
```

### Customers of the top 4 product: do they also buy other goods?
```{r eval = T}
# Change isTop to factor for grouping
retail$isTop <- factor(retail$isTop)
# retail$CustomerID <- factor(retail$CustomerID)

# Summary stats for top 4 product consumers
consumer_summary <- retail %>% 
  group_by(CustomerID) %>% 
  filter(isTop != 0) %>% 
  summarise(min_price = min(UnitPrice),
            mean_price = mean(UnitPrice),
            max_price = max(UnitPrice),
            min_purchase = min(Quantity), 
            ave_purchase = mean(Quantity),
            max_purchase = max(Quantity),
            ave_spending = mean(Revenue),
            other_purchase = length(unique(isTop))) %>% 
  arrange(-ave_spending)
summary(consumer_summary) 

# other_purchase > 1 indicate not only purchase one product
multi_buyer <- consumer_summary %>% filter(other_purchase > 1) %>% select(CustomerID)
nrow(multi_buyer) 
# Seems like 748 of the top4 product consumers purchase more than
# one product (maybe bundling since those are party decorations)

```

### Heatmaps for monthly sales visualization
```{r eval = T}
retail_time <- retail %>% filter(!is.na(InvoiceDate))
# retail$InvoiceDate <- as.POSIXct(mytime$InvoiceDate, format="%m/%d/%y %H:%M")
retail_time$InvoiceDate <- as.Date(retail_time$InvoiceDate, format = "%m/%d/%y")
retail_time$Month <- month(retail_time$InvoiceDate)
# summary(retail_time$InvoiceDate)
# Time from 2010-12-01 to 2011-12-09(roughly a 12 month period)
# Heatmap: total revenue for each product in each month
monthly_revenue <- retail_time %>% 
  group_by(Month) %>% 
  summarise(CakeStand = sum(Revenue[Description == top4_product[1]]),
            PartyBunting = sum(Revenue[Description == top4_product[2]]),
            LightHolder = sum(Revenue[Description == top4_product[3]]),
            JumboBag = sum(Revenue[Description == top4_product[4]])
            )
heatmaply(as.matrix(monthly_revenue[, -1]), Rowv = NA, Colv = NA, 
          xlab = "Top 4 Selling Products", ylab = "Month",
          main = "Total Monthly Revenue for each Product")

# Heatmap: total Qty sold for each product in each month
monthly_sales <- retail_time %>% 
  group_by(Month) %>% 
  summarise(CakeStand = sum(Quantity[Description == top4_product[1]]),
            PartyBunting = sum(Quantity[Description == top4_product[2]]),
            LightHolder = sum(Quantity[Description == top4_product[3]]),
            JumboBag = sum(Quantity[Description == top4_product[4]])
  )
heatmaply(as.matrix(monthly_sales[, -1]), Rowv = NA, Colv = NA, 
          xlab = "Top 4 Selling Products", ylab = "Month",
          main = "Total Monthly Qty Sold for each Product")
```

### Consumer side analysis: compare unique items bought
``` {r eval = T}
# Consumer analysis from top 4 products
# Obtain customer ID's of those who purchased one of the top 4

top_4_purchasers <- retail %>%
  na.omit(retail) %>%
  filter(isTop != 0 & Quantity > 0 & UnitPrice > 0) %>%
  select(CustomerID)
top_4_purchasers <- unique(top_4_purchasers$CustomerID)
top_product_purchasers <- retail %>%
  filter(CustomerID %in% top_4_purchasers)
nrow(top_product_purchasers)
# 305,332 observations (i.e. sales) in this data frame, out of
# all 406,829 observations with NA's omitted. This is filtered by
# customers who purchased at least one of the top 4 products. So, it shows
# that customers who buy the top products tend to be "the best"
# customers too, because they compose the bulk of the business
# for this online retailer. Digging deeper now
names(top_product_purchasers)
top_purchasers_analysis <- top_product_purchasers %>%
  group_by(CustomerID) %>%
  summarise(min_price = min(UnitPrice),
            max_price = max(UnitPrice), sd_price = sd(UnitPrice),
            avg_price = mean(UnitPrice),
            min_sold = min(Quantity), max_sold = max(Quantity),
            avg_sold = mean(Quantity),
            num_top_4_bought = length(unique(isTop)),
            num_unique_prod_bought = length(unique(Description)),
            is_top_purchaser = TRUE
            )
top_purchasers_products <- 
  top_purchasers_analysis[, c("CustomerID",
                            "num_unique_prod_bought",
                            "is_top_purchaser")]
  
# Let's also grab all consumers who did NOT purchase a top 4
# product and conduct a similar analysis.
non_top_purchasers <- retail %>%
  na.omit(retail) %>%
  filter(isTop == 0 & !(CustomerID %in% top_4_purchasers)) %>%
  select(CustomerID)
non_top_purchasers <- unique(non_top_purchasers$CustomerID)
non_top_product_purchasers <- retail %>%
  filter(CustomerID %in% non_top_purchasers)
non_top_purchasers_analysis <- non_top_product_purchasers %>%
  group_by(CustomerID) %>%
  summarise(min_price = min(UnitPrice),
            max_price = max(UnitPrice), sd_price = sd(UnitPrice),
            avg_price = mean(UnitPrice),
            min_sold = min(Quantity), max_sold = max(Quantity),
            avg_sold = mean(Quantity),
            num_unique_prod_bought =length(unique(Description)),
            is_top_purchaser = FALSE)
non_top_purchasers_products <-
  non_top_purchasers_analysis[, c("CustomerID",
                                  "num_unique_prod_bought",
                                  "is_top_purchaser")]
all_purchasers_products <- rbind(top_purchasers_products,
                                 non_top_purchasers_products)
# Visualize box plots for number of unique products purchased
# amongst those who buy one (or more) of the top 4 products
# versus those who do not buy any of the top 4 products.

# This one shows full distribution.
purchaser_boxplot_full <- ggplot(all_purchasers_products,
                            aes(x=as.factor(is_top_purchaser),
                                y=num_unique_prod_bought)) +
  geom_boxplot(outlier.color = "red", outlier.size = 3) +
  labs(x = "Consumer is a purchaser of a top 4 product",
       y = "Number of Unique Products Purchased")
purchaser_boxplot_full
# This one excludes the largest outliers to get a better view
purchaser_boxplot_partial <-
  ggplot(all_purchasers_products,
         aes(x=as.factor(is_top_purchaser),
             y=num_unique_prod_bought)) +
  geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(name = "Number of Unique Products Purchased",
                   limits = c(0, 300), breaks = seq(0, 300, 25)) +
  labs(x = "Consumer is a purchaser of a top 4 product")
purchaser_boxplot_partial

# Top 4 products summary
top_products <- retail %>%
  filter(Description %in% top4_product & Quantity > 0 &
           UnitPrice > 0)

top_products_summary <- top_products %>%
  group_by(isTop) %>%
  summarise(min_price = min(UnitPrice),
            max_price = max(UnitPrice),
            sd_price = sd(UnitPrice),
            avg_price = mean(UnitPrice),
            min_sold = min(Quantity),
            max_sold = max(Quantity),
            avg_sold = mean(Quantity),
            total_sold = sum(Quantity),
            total_revenue = sum(revenue),
            avg_revenue = mean(revenue))
top_products_summary
# Small price standard deviation for products 3 and 4, pretty 
# large price standard deviations for products 1 and 2. However,
# products 3 and 4 tend to be sold more than products 1 and 2.
```

### Time series analysis for amount sold of top 4 product & line visualization:
```{r eval = T}
# Time Series Component
time_data <- retail %>%
  mutate(time_stamp = mdy_hm(InvoiceDate))
time_data <- time_data %>%
  mutate(month = month(time_stamp), year = year(time_stamp),
         hour = hour(time_stamp))

# Let's start by looking at raw sales numbers for our top 4
# products over 2011.
# rm(time_products)
time_products_month <- time_data %>%
  filter(year == 2011, Description %in% top4_product,
         Quantity > 0, UnitPrice > 0) %>%
  group_by(Description, month) %>%
  summarise(total_sold = sum(Quantity),
            avg_sold = mean(Quantity))
time_products_month

time_products_hour <- time_data %>%
  filter(year == 2011, Description %in% top4_product,
         Quantity > 0, UnitPrice > 0) %>%
  group_by(Description, hour) %>%
  summarise(total_sold = sum(Quantity),
            avg_sold = mean(Quantity))
time_products_vis_month <- ggplot(time_products_month,
                            aes(x = month, y = total_sold,
                                group = Description)) +
  geom_line(aes(linetype = Description)) +
  scale_x_continuous(limits = c(0,12), breaks = seq(0,12,1)) +
  theme_minimal() +
  facet_grid(rows =  vars(Description))
time_products_vis_month

time_products_vis_avg_month <- ggplot(time_products_month,
                            aes(x = month, y = avg_sold,
                                group = Description)) +
  geom_line(aes(linetype = Description)) +
  scale_x_continuous(limits = c(0,12), breaks = seq(0,12,1)) +
  theme_minimal() +
  facet_grid(rows = vars(Description))
time_products_vis_avg_month

time_products_vis_hour <- ggplot(time_products_hour,
                                 aes(x=hour, y=total_sold,
                                     group=Description)) +
  geom_line(aes(linetype = Description)) +
  theme_minimal() +
  facet_grid(rows = vars(Description))
time_products_vis_hour

time_products_vis_avg_hour <- ggplot(time_products_hour,
                                     aes(x=hour, y=avg_sold,
                                         group=Description)) +
  geom_line(aes(linetype = Description)) +
  theme_minimal() +
  facet_grid(rows = vars(Description))
time_products_vis_avg_hour
```

### Consumer analysis: big spender vs non-spender
```{r eval = T}
# Moving onto customers
# Want to differentiate between big spenders and non-big spenders
# Will classify big spenders as those who, on average, spend
# more than the mean price, while non-big spenders will, on average,spend less than the mean price 

# Get mean statistics for price and quantity.
mean_stats <- time_data %>%
  summarise(mean_price = mean(UnitPrice))
mean_stats
mean_price <- mean_stats$mean_price
# Filter for big and non-big spenders as described above.
mean_spending <- time_data %>%
  group_by(CustomerID) %>%
  mutate(mean_price_paid = mean(UnitPrice))
big_spenders <- mean_spending %>%
  na.omit(mean_spending) %>%
  filter(mean_price_paid >= mean_price & year == 2011)
non_big_spenders <- mean_spending %>%
  na.omit(mean_spending) %>%
  filter(mean_price_paid < mean_price & year == 2011)
# Get average and total quantities/revenues for both types of
# customers
big_spenders_data <- big_spenders %>%
  group_by(month) %>%
  summarise(total_bought = sum(Quantity),
            mean_bought = mean(Quantity),
            total_revenue = sum(revenue),
            mean_revenue = mean(revenue),
            mean_price = mean(UnitPrice))
non_big_spenders_data <- non_big_spenders %>%
  group_by(month) %>%
  summarise(total_bought = sum(Quantity),
            mean_bought = mean(Quantity),
            total_revenue = sum(revenue),
            mean_revenue = mean(revenue),
            mean_price = mean(UnitPrice))
# Merge all consumer spending data together, rename columns
all_spenders_data <- merge(big_spenders_data,
                           non_big_spenders_data,
                           by=c("month"))
all_spenders_data <- all_spenders_data %>%
  rename(total_bought_big = total_bought.x,
         mean_bought_big = mean_bought.x,
         total_revenue_big = total_revenue.x,
         mean_revenue_big = mean_revenue.x,
         total_bought_non = total_bought.y,
         mean_bought_non = mean_bought.y,
         total_revenue_non = total_revenue.y,
         mean_revenue_non = mean_revenue.y,
         mean_price_big = mean_price.x,
         mean_price_non = mean_price.y)
all_spenders_data

# Create some visualizations
all_spenders_revenue <- ggplot(all_spenders_data,
                               aes(x=month)) +
  geom_line(aes(y=mean_revenue_big, color="big spenders")) +
  geom_line(aes(y=mean_revenue_non, color="non-big spenders"),
            linetype = "twodash") +
  labs(y = "Mean revenue",
       title ="Tracking average revenue by type of spender") +
  scale_x_continuous(limits=c(1,12), breaks=seq(1,12,1)) +
  scale_color_manual(breaks = c("big spenders", "non-big spenders"),
                     values = c("red", "blue"))
all_spenders_revenue

all_spenders_data
all_spenders_sales <- ggplot(all_spenders_data, aes(x=month)) +
  geom_line(aes(y=mean_bought_big, color = "big spenders")) +
  geom_line(aes(y=mean_bought_non, color = "non-big spenders"),
            linetype="dashed") +
  labs(y = "Average Quantity Purchased",
       title = "Tracking average quantities sold by type of spender") +
  scale_x_continuous(limits=c(1,12), breaks=seq(1,12,1)) +
  scale_color_manual(breaks = c("big spenders", "non-big spenders"),
                     values = c("red", "blue"))
all_spenders_sales
# Mean revenue has a gap between the big spenders versus the
# non-big spenders, but that's to be expected somewhat given
# how we defined what a big spender is. What's more interesting
# is the quite large discrepancy between the average number of
# products purchased by big spenders compared to non-big spenders.
# This is pretty consistent across all months of 2011. Non-big
# spenders tend to purchase more goods per month, but at the reduced
# price, we do not extract nearly as much revenue from these individuals.

# Get average quantities bought/price paid by the top 4 customers over
# 2011.
top_4_data <- time_data %>%
  filter(CustomerID %in% top_4_customers) %>%
  group_by(CustomerID, month) %>%
  filter(Quantity > 0 & UnitPrice > 0) %>%
  summarise(avg_quantity_bought = mean(Quantity),
            avg_price_paid = mean(UnitPrice))
top_4_quant_vis <- ggplot(top_4_data, aes(x=month,
                                                y=avg_quantity_bought)) +
  geom_line(aes(color = as.factor(CustomerID))) + geom_point() +
  scale_x_continuous(limits=c(1,12), breaks=seq(1,12,1)) +
  labs(color = "CustomerID", title = "Average sales by top 4 customers",
       y = "Average Quantity")
top_4_quant_vis
top_4_data
top_4_price_vis <- ggplot(top_4_data, aes(x=month, y=avg_price_paid)) +
  geom_line(aes(color=as.factor(CustomerID))) + geom_point() +
  scale_x_continuous(limits=c(1,12), breaks=seq(1,12,1)) +
  labs(title = "Average price paid by top 4 customers",
       color = "CustomerID", y = "Average Price")
top_4_price_vis
```

### Following above revenue shares analysis: further break down revenue shares of each product by type of consumer(top4, top10 or else).
```{r eval = T}
# Create new columns indicate top4 and top10 consumer
retail$Top4_Buyer <- retail$CustomerID %in% top_4_customers
retail$Top4_Buyer <- factor(retail$Top4_Buyer, levels = c(T, F))
retail$Top10_Buyer <- retail$CustomerID %in% top_10_customers
retail$Top10_Buyer <- factor(retail$Top10_Buyer, levels = c(T, F))

# Each consumer type's revenue for each product
share_detail <- retail %>% 
  group_by(isTop) %>% 
  summarise(Top4_Revenue = sum(Revenue[Top4_Buyer == T]),
            Top10_Revenue = sum(Revenue[Top10_Buyer == T]),
            Total_Revenue = sum(Revenue))

# Get the differences for graphing
share_detail$Total_Revenue <- share_detail$Total_Revenue-share_detail$Top10_Revenue
share_detail$Top10_Revenue <- share_detail$Top10_Revenue-share_detail$Top4_Revenue
# Get percentage
for (i in 2:4){
  share_detail[, i] = share_detail[, i]/sum(retail$Revenue) * 100
}
share_detail

# Stacked Histograms:
stack_hist <- share_detail %>% gather(ConsumerType, Percentage, 2:4)
stack_hist$ConsumerType = factor(stack_hist$ConsumerType,
                                 levels=c("Total_Revenue","Top10_Revenue", "Top4_Revenue"))
# Including the non-top4 product
ggplot(stack_hist, aes(fill=ConsumerType, y=Percentage, x=isTop)) + 
  geom_bar(position="stack", stat="identity") +
  labs(title = "Revenue Share of Top 4 Product (break down by consumer type)")

# Top4 product only
ggplot(stack_hist %>% filter(isTop!=0), aes(fill=ConsumerType, y=Percentage, x=isTop)) + 
  geom_bar(position="stack", stat="identity") +
  labs(title = "Revenue Share of Top 4 Product (break down by consumer type)")
```

### Elasticity estimates: segment by the top 10 spending buys in our 4 products
```{r}
# Find top 10 revenue contributor in top selling products
top_consumer <- retail %>% 
  filter(!is.na(CustomerID), isTop != 0) %>% 
  group_by(CustomerID) %>% 
  summarise(Spending = sum(Revenue)) %>% 
  arrange(-Spending)

top10_buyer <- top_consumer$CustomerID[1:10]
retail$Top10_Buyer <- retail$CustomerID %in% top10_buyer
retail$Top10_Buyer <- factor(retail$Top10_Buyer, levels = c(T, F))

# Elasticity estimates: by top 10 buyers of the top selling products

# Check number of obs we can work with
retail$isTop = factor(retail$isTop)
transaction_summary <- retail %>% 
  group_by(isTop) %>% 
  summarise(transactions = length(CustomerID),
            top10_buyer = sum(Top10_Buyer==T),
            other_buyer = sum(Top10_Buyer==F))
transaction_summary

# Function to estimate
estimate_elasticity <- function(i){
  product <- retail %>% 
    filter(Description == top4_product[i], Quantity > 0, UnitPrice > 0) %>% 
    select(Quantity, UnitPrice, Top10_Buyer)
  
  fit <- lm(log(Quantity)~log(UnitPrice)*Top10_Buyer, data = product)
  
  print(paste("Standard Deviation on price"), sd(product$UnitPrice))
  print(paste("Average price"), mean(product$UnitPrice))
  print(summary(fit))
  
  estimate <- c(summary(fit)$coef[2],
                summary(fit)$coef[2]+summary(fit)$coef[4])
  return (estimate)
}

Elasticity_top_buyer <- data.frame("CakeStand"= rep(0, 2), "PartyBunting"=rep(0, 2),
                                     "LightHolder"=rep(0, 2), "JumboBag"=rep(0, 2))
rownames(Elasticity_top_buyer) <- c("Top Buyer", "Other Buyer")

for (i in 1:4){
  Elasticity_top_buyer[[i]] <- estimate_elasticity(i)
}
Elasticity_top_buyer
# All coefficient significant

# Combing the elasticity result with above revenue share stack bar chart,
# maybe can consider discount price lower to boost sales from our top4 or 
# top10 buyers since they are more elastic(if calculation above is correct),
# and shade price lower for those who contribute less to our revenue since
# since they are more inelastic anyways. 
```

### Visualize top buyer purchasing behavior
```{r}
retail$InvoiceDate <- as.Date(retail$InvoiceDate, format = "%m/%d/%y")
retail$Month <- month(retail$InvoiceDate)

# Line graph
top10_buying_pattern <- retail %>% 
  filter(Description %in% top4_product, CustomerID %in% top10_buyer) %>% 
  group_by(Month, CustomerID) %>% 
  summarise(Monthly_Spending = sum(Revenue))
top10_buying_pattern$CustomerID <- as.character(top10_buying_pattern$CustomerID)

ggplot(data=top10_buying_pattern,mapping =aes(x=Month,y=Monthly_Spending))+
  geom_point() +
  geom_line(aes(color=CustomerID)) +
  scale_x_continuous(breaks = c(1:12)) +
  labs(title = "Monthly Revenue from Each Top 10 Buyer") +
  theme(plot.title = element_text(hjust = 0.5, size = 15))
```

### Elasticity estimate: by domestic vs. export
```{r}
# Get a peak on the obs we can work with
retail$isTop = factor(retail$isTop)
transaction_summary <- retail %>% 
  group_by(isTop) %>% 
  summarise(transactions = length(CustomerID),
            uk_sales = sum(Country == "United Kingdom"),
            non_uk = sum(Country != "United Kingdom"))
transaction_summary
# Not many obs for non-uk sales, elasticity estimate
# for non-uk sales might be weird

UK_elasticity <- function(i) {
  product_all <- retail %>% 
    filter(Description == top4_product[4]) %>% 
    select(Quantity, UnitPrice, CustomerID, Country)

  product <- product_all %>% filter(Quantity > 0, UnitPrice > 0)

  # Use UK as base group cuz that most of our sales goes there (assume it's a UK business?) 
  # Try see if elasticity is different for UK vs. non-UK sales
  product$UK <- product$Country == "United Kingdom"
  product$UK <- factor(product$UK, levels = c(T, F))

  #  Elasticity estimate: log_qty on log_price for UK vs. Non_UK
  fit_country <- lm(log(Quantity)~log(UnitPrice)*UK, data = product)
  
  print(paste("Standard Deviation on price"), sd(product$UnitPrice))
  print(paste("Average price"), mean(product$UnitPrice))
  print(summary(fit_country))
  
  # Checking regression in sample performance, in-sample MSE
  print(mean((log(product$Quantity) - predict(fit_country))^2))
  
  estimate <- c(summary(fit_country)$coef[2],
                summary(fit_country)$coef[2]+summary(fit_country)$coef[4])
  
  return(estimate)
}

Elasticity_by_country <- data.frame("CakeStand"= rep(0, 2), "PartyBunting"=rep(0, 2),
                                  "LightHolder"=rep(0, 2), "JumboBag"=rep(0, 2))
rownames(Elasticity_by_country) <- c("UK", "Non-UK")

for (i in 1:4) {
  Elasticity_by_country[[i]] <- UK_elasticity(i)
}
Elasticity_by_country
# Each product coefficient significance & R^2:
# 1. All significant & R^2 = 0.17 
# 2. All significant & R^2 = 0.07 (too low)
# 3. All significant & R^2 = 0.22
# 4. All significant & R^2 = 0.299 
# If looking at just the elasticity measures, seems like domestic sales
# tend to be much less elastic than exports, which might motivate firm to
# price differently, but again th R^2 is too low here so conclusion might
# not hold true.
```

### Top 4 buyer bundling behavior
```{r eval = T, message = F}
# Mateo's pairing function changing a bit, group by StockID instead
# cuz there's one weird string forproduct Description that doesn't work

#Sold together function, it takes the product names as strings
pair_function1 <- function(product1, product2) {
  product_1_dataframe <- retail %>% 
    filter(StockCode == product1) %>%
    filter(Quantity>0) %>% 
    group_by(InvoiceNo) %>% 
    summarise(sum(Quantity))
  product_2_dataframe <- retail %>%
    filter(StockCode == product2) %>%
    filter(Quantity>0) %>% 
    group_by(InvoiceNo) %>% 
    summarise(sum(Quantity))
  product_1_2_dataframe <- merge(product_1_dataframe, product_2_dataframe, by= "InvoiceNo")
  percentage_1 <- round(nrow(product_1_2_dataframe)/nrow(product_1_dataframe) *100, digits = 2)
  percentage_2 <- round(nrow(product_1_2_dataframe)/nrow(product_2_dataframe) *100, digits = 2)
  #print(paste(product1, "is bought", percentage_2, "percent of the time with", product2))
  return(percentage_2) # given product 2 is bought, prob of buying product 1
}

top_consumer <- retail %>% 
  filter(!is.na(CustomerID)) %>% 
  group_by(CustomerID) %>% 
  summarise(Spending = sum(Revenue)) %>% 
  arrange(-Spending)
top4_buyer <- top_consumer$CustomerID[1:4]

# Summarise what products top customers buy
buyers_choice_summary <- retail %>% 
  filter(CustomerID %in% top4_buyer) %>% 
  group_by(CustomerID, StockCode) %>% 
  summarise(Qty_purchase = length(StockCode),
            Unique_month = length(unique(Month)),
            Revenue = sum(Revenue))
length(unique(buyers_choice_summary$StockCode)) # only buys 2021/4070 unique products

choices <- buyers_choice_summary %>% 
  group_by(StockCode) %>% 
  summarise(Total_Qty_Sold = sum(Qty_purchase),
            Total_Spending = sum(Revenue),
            Unique_Buyer = length(unique(CustomerID))) %>% 
  arrange(Unique_Buyer)

# Get items that all 4 consumer buys
common_choiceID <- choices %>% filter(Unique_Buyer == 4, StockCode != "M") # Mannual
common_choiceID <- common_choiceID$StockCode
for (i in 1:length(common_choiceID)){
  print(retail %>% filter(StockCode == common_choiceID[i]) %>% select(Description) %>% unique())
}
common_choice <- c("DOORMAT RED RETROSPOT",
                   "MEMO BOARD RETROSPOT  DESIGN",
                   "RECIPE BOX PANTRY YELLOW DESIGN",
                   "   SET OF 3 CAKE TINS PANTRY DESIGN ",
                   "JAM MAKING SET WITH JARS",
                   "SET OF TEA COFFEE SUGAR TINS PANTRY",
                   "DOORMAT ENGLISH ROSE ")
common_choice_short <- c("DOORMAT RED",
                         "MEMO BOARD",
                         "RECIPE BOX PANTRY",
                         "SET OF CAKE TINS",
                         "JAM MAKING SET",
                         "TEA/COFFEE/SUGAR TINS",
                         "DOORMAT ROSE")

# Top 5 most sold products
choices <- choices %>% arrange(-Total_Spending)
most_soldID <- as.vector(choices$StockCode[1:5]) # C2 is carriage
for (i in 1:length(most_soldID)){
  print(retail %>% filter(StockCode == most_soldID[i]) %>% select(Description) %>% unique())
}
most_sold <- c("VINTAGE UNION JACK MEMOBOARD",
               "WHITE HANGING HEART T-LIGHT HOLDER",
               "WOOD BLACK BOARD ANT WHITE FINISH",
               "CREAM HEART CARD HOLDER",
               "HEART OF WICKER LARGE")
most_sold_short <- c("VINTAGE MEMOBOARD",
                     "LIGHT HOLDER",
                     "WOOD BLACK BOARD",
                     "HEART CARD HOLDER",
                     "HEART OF WICKER")

# Bundling pattern for top 4 buyer's common choice
x <- rep(0, length(common_choice))
bundling_pattern <- data.frame(x, x, x, x, x, x, x)
colnames(bundling_pattern) <- common_choice_short
rownames(bundling_pattern) <- common_choice_short

for (i in 1:length(common_choice)){
  item <- rep(0, length(common_choice))
  for (j in 1:7){
    item[j] <- pair_function1(common_choiceID[i], common_choiceID[j])
  }
  bundling_pattern[[i]] <- item
}

heatmaply(as.matrix(bundling_pattern), Rowv = NA, Colv = NA, 
          main = "Common Purchased Products Top 4 Buyers")

# Bundling pattern for top 5 most sold items
y <- rep(0, length(most_sold))
bundling_pattern1 <- data.frame(y, y, y, y, y)
colnames(bundling_pattern1) <- most_sold_short
rownames(bundling_pattern1) <- most_sold_short

for (i in 1:length(most_soldID)){
  item <- rep(0, length(most_soldID))
  for (j in 1:length(most_soldID)){
    item[j] <- pair_function1(most_soldID[i], most_soldID[j])
  }
  bundling_pattern1[[i]] <- item
}

heatmaply(as.matrix(bundling_pattern1), Rowv = NA, Colv = NA, 
          main = "Top 5 Most Sold Items by Top Purchaser")

